{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Player Detection"
      ],
      "metadata": {
        "id": "zbL5iLyEoy1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU + Drive"
      ],
      "metadata": {
        "id": "GrzNpxYOo8R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi -L || echo \"No GPU detected (enable GPU: Runtime → Change runtime type)\"\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base path in Drive\n",
        "BASE = \"/content/drive/MyDrive/DS5216\"\n",
        "print(\"Using base:\", BASE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4_75cr5o754",
        "outputId": "0f7ce27c-fd7b-48ad-ee10-e31ee1e94d4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "LhDbq3AXpJnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0YWfAlWonHf",
        "outputId": "c88d405d-5eda-4307-99db-08e41b7ec4d1"
      },
      "outputs": [],
      "source": [
        "!pip -q install ultralytics==8.3.34 supervision==0.22.0 opencv-python-headless==4.10.0.84 yt-dlp==2024.10.07\n",
        "!apt -y install ffmpeg > /dev/null\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Imports & folders"
      ],
      "metadata": {
        "id": "fCRkN0gxpOlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os, glob, json, cv2, numpy as np, pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from datetime import datetime\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# Folders\n",
        "DATA_DIR = Path(BASE) / \"data\"\n",
        "VID_DIR  = DATA_DIR / \"videos\"\n",
        "OUT_DIR  = Path(BASE) / \"outputs\"\n",
        "SS_DIR   = Path(BASE) / \"screenshots\"\n",
        "for p in [DATA_DIR, VID_DIR, OUT_DIR, SS_DIR]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Folders:\")\n",
        "print(\"-\", VID_DIR)\n",
        "print(\"-\", OUT_DIR)\n",
        "print(\"-\", SS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgBUIlYnpNaf",
        "outputId": "6cdf1567-1f88-4f24-d74d-f26f0a4c7a2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add videos"
      ],
      "metadata": {
        "id": "Qm7Ui7s3pXgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List videos found\n",
        "videos = sorted(glob.glob(str(VID_DIR / \"*.mp4\")) +\n",
        "                glob.glob(str(VID_DIR / \"*.mkv\")) +\n",
        "                glob.glob(str(VID_DIR / \"*.mov\")) +\n",
        "                glob.glob(str(VID_DIR / \"*.webm\")))\n",
        "print(f\"Found {len(videos)} video(s):\")\n",
        "for v in videos: print(\"-\", Path(v).name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDWoiz2FpajX",
        "outputId": "837c2bd4-32c9-4141-c6e5-220399f61fd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "srQ4Xu7-pftY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "det_model = YOLO(\"yolov8n.pt\")\n",
        "PERSON_CLASS_ID = 0\n",
        "print(\"yolov8n.pt Model ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejwwUkbpbdb",
        "outputId": "cbd0b275-7008-4c25-95fe-ace1daccad58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking"
      ],
      "metadata": {
        "id": "oZKCJNhPpnKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def track(\n",
        "    src_path,\n",
        "    save_prefix=\"yolo8n\",\n",
        "    conf=0.35,\n",
        "    iou=0.45,\n",
        "    tracker=\"bytetrack.yaml\",\n",
        "    take_screens=5\n",
        "):\n",
        "    src = Path(src_path)\n",
        "    name = src.stem.strip().replace(\" \", \"_\")\n",
        "\n",
        "    # Probe video for size/FPS\n",
        "    cap = cv2.VideoCapture(str(src))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open video: {src}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    if fps <= 1: fps = 30.0\n",
        "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1280\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 720\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
        "    cap.release()\n",
        "\n",
        "    # Output paths\n",
        "    out_video_path = OUT_DIR /\"Player Detection\"/ f\"{save_prefix}_{name}_tracked.mp4\"\n",
        "    out_json_path  = OUT_DIR /\"Player Detection\"/f\"{save_prefix}_{name}_stats.json\"\n",
        "\n",
        "    # VideoWriter (MP4 → fallback to AVI if needed)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(str(out_video_path), fourcc, fps, (width, height))\n",
        "    if not writer.isOpened():\n",
        "        out_video_path = OUT_DIR / f\"{save_prefix}_{name}_tracked.avi\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(str(out_video_path), fourcc, fps, (width, height))\n",
        "        if not writer.isOpened():\n",
        "            raise RuntimeError(\"Failed to open VideoWriter for both MP4 and AVI.\")\n",
        "\n",
        "    # Screenshots positions\n",
        "    shot_positions = []\n",
        "    if total_frames > 0:\n",
        "        take = min(take_screens, total_frames) if total_frames < take_screens else take_screens\n",
        "        shot_positions = [int((i+1) * total_frames / (take+1)) for i in range(take)]\n",
        "    screenshot_buffer = {}\n",
        "\n",
        "    # Stats\n",
        "    frame_idx = 0\n",
        "    frame_counts = []\n",
        "    track_ids_seen = set()\n",
        "    id_switches = 0\n",
        "    prev_frame_ids = set()\n",
        "\n",
        "    # Stream detections (no RAM buildup)\n",
        "    gen = det_model.track(\n",
        "        source=str(src),\n",
        "        conf=conf, iou=iou, classes=[PERSON_CLASS_ID],\n",
        "        tracker=tracker,\n",
        "        save=False, stream=True, verbose=False\n",
        "    )\n",
        "\n",
        "    for r in gen:\n",
        "        frame = r.plot()           # annotated frame (BGR)\n",
        "        writer.write(frame)\n",
        "\n",
        "        # Stats via track IDs\n",
        "        ids = []\n",
        "        if r.boxes is not None and r.boxes.id is not None:\n",
        "            ids = [int(x) for x in r.boxes.id.cpu().numpy().tolist()]\n",
        "        frame_counts.append(len(ids))\n",
        "        new_ids = set(ids)\n",
        "        appeared = new_ids - prev_frame_ids\n",
        "        disappeared = prev_frame_ids - new_ids\n",
        "        if appeared and disappeared:\n",
        "            id_switches += min(len(appeared), len(disappeared))\n",
        "        prev_frame_ids = new_ids\n",
        "        track_ids_seen.update(ids)\n",
        "\n",
        "        # Save screenshots\n",
        "        if frame_idx in shot_positions:\n",
        "            screenshot_buffer[frame_idx] = frame.copy()\n",
        "        frame_idx += 1\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "    # Write screenshots\n",
        "    for pos, img in screenshot_buffer.items():\n",
        "        cv2.imwrite(str(SS_DIR / f\"{save_prefix}_{name}_frame{pos}.jpg\"), img)\n",
        "\n",
        "    # Save stats\n",
        "    stats = {\n",
        "        \"video\": src.name,\n",
        "        \"frames_processed\": len(frame_counts),\n",
        "        \"mean_persons_per_frame\": float(np.mean(frame_counts)) if frame_counts else 0.0,\n",
        "        \"max_persons_in_frame\": int(np.max(frame_counts)) if frame_counts else 0,\n",
        "        \"unique_track_ids\": len(track_ids_seen),\n",
        "        \"approx_id_switches\": int(id_switches),\n",
        "        \"conf\": conf, \"iou\": iou, \"tracker\": tracker,\n",
        "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "    }\n",
        "    with open(out_json_path, \"w\") as f:\n",
        "        json.dump(stats, f, indent=2)\n",
        "\n",
        "    print(\"Saved video:\", out_video_path)\n",
        "    print(\"Saved stats:\", out_json_path)\n",
        "    return out_video_path, out_json_path\n"
      ],
      "metadata": {
        "id": "dOP955TvpbZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Run on all videos"
      ],
      "metadata": {
        "id": "--d36_ykptod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated = []\n",
        "for v in videos:\n",
        "    out_vid, out_json = track(v, save_prefix=\"yolo8n\")\n",
        "    generated.append((out_vid, out_json))\n",
        "\n",
        "print(\"\\nGenerated files:\")\n",
        "for v, j in generated:\n",
        "    print(\"-\", Path(v).name, \"|\", Path(j).name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBpZKcAzpbXq",
        "outputId": "e1f1f8b4-587e-4a9b-e810-a06f6c7b80d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Make a CSV summary"
      ],
      "metadata": {
        "id": "aw9i7sSyqB2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for js in glob.glob(str(OUT_DIR / \"*_stats.json\")):\n",
        "    with open(js) as f:\n",
        "        rows.append(json.load(f))\n",
        "df = pd.DataFrame(rows)\n",
        "if not df.empty:\n",
        "    df = df[[\"video\",\"frames_processed\",\"mean_persons_per_frame\",\"max_persons_in_frame\",\n",
        "             \"unique_track_ids\",\"approx_id_switches\",\"conf\",\"iou\",\"tracker\",\"timestamp\"]]\n",
        "    df.sort_values(\"video\", inplace=True, ignore_index=True)\n",
        "\n",
        "csv_path = OUT_DIR / \"tracking_summary.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"Saved:\", csv_path)\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "goV29oTgpbSt",
        "outputId": "0a6f804c-cc08-4990-c0e1-9391ace67e8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune model"
      ],
      "metadata": {
        "id": "aA82NeaM4R-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_YAML = f\"{BASE}/data/person_dataset/person.yaml\"\n",
        "PROJECT_TRAIN = f\"{BASE}/exp_det_train\"\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "r = model.train(\n",
        "    data=DATA_YAML, epochs=20, imgsz=640, batch=16, device=0,\n",
        "    project=PROJECT_TRAIN, name=\"person_y8n_ft\", verbose=False\n",
        ")\n",
        "best = Path(r.save_dir) / \"weights/best.pt\"\n",
        "best\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAtbm_qi4fNK",
        "outputId": "c356c9e9-1a93-473b-c03a-c056f43b87e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training loss curves"
      ],
      "metadata": {
        "id": "gzaRvs2w4kbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, matplotlib.pyplot as plt, glob, os\n",
        "\n",
        "csv = sorted(glob.glob(f\"{PROJECT_TRAIN}/person_y8n_ft/results.csv\"))[-1]\n",
        "df = pd.read_csv(csv)\n",
        "\n",
        "for col in [\"train/box_loss\",\"train/cls_loss\",\"train/dfl_loss\",\n",
        "            \"metrics/precision(B)\",\"metrics/recall(B)\",\"metrics/mAP50(B)\",\"metrics/mAP50-95(B)\"]:\n",
        "    if col in df.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df[\"epoch\"], df[col])\n",
        "        plt.title(col)\n",
        "        plt.xlabel(\"Epoch\"); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E-ym1eKf4mte",
        "outputId": "76fcfba7-0183-4eb1-eb16-22a660aba5e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate baseline vs fine-tuned on the same val set"
      ],
      "metadata": {
        "id": "Jy-FQguo5Otp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "\n",
        "DATA_YAML = f\"{BASE}/data/person_dataset/person.yaml\"\n",
        "PROJECT_VAL = f\"{BASE}/exp_det_eval2\"\n",
        "weights_to_compare = [\"yolov8n.pt\", str(best)]  # baseline vs fine-tuned\n",
        "rows = []\n",
        "\n",
        "for w in weights_to_compare:\n",
        "    res = YOLO(w).val(data=DATA_YAML, imgsz=640, plots=True, save_json=True,\n",
        "                      project=PROJECT_VAL, name=f\"val_{Path(w).stem}\", verbose=False)\n",
        "    d = res.results_dict\n",
        "    rows.append({\n",
        "        \"weights\": Path(w).name,\n",
        "        \"mAP50-95\": d.get(\"metrics/mAP50-95(B)\", d.get(\"metrics/mAP50-95\")),\n",
        "        \"mAP50\":    d.get(\"metrics/mAP50(B)\",    d.get(\"metrics/mAP50\")),\n",
        "        \"precision\":d.get(\"metrics/precision(B)\",d.get(\"precision\")),\n",
        "        \"recall\":   d.get(\"metrics/recall(B)\",   d.get(\"recall\")),\n",
        "        \"inference_ms\": d.get(\"speed/inference\")\n",
        "    })\n",
        "\n",
        "df_cmp = pd.DataFrame(rows)\n",
        "df_cmp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "_AI2gLke5QnJ",
        "outputId": "5061c69b-f9bf-4ac6-b297-ff9e7d1448f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export a clean table & copy key figures"
      ],
      "metadata": {
        "id": "_u5csIWR5c0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cmp_csv = f\"{BASE}/outputs/det_comparison.csv\"\n",
        "Path(f\"{BASE}/outputs\").mkdir(parents=True, exist_ok=True)\n",
        "df_cmp.to_csv(cmp_csv, index=False)\n",
        "print(\"Saved:\", cmp_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXKrSCQn5fkx",
        "outputId": "3c069ed0-ad9c-4379-f280-2b3f64b5945a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose a confidence threshold using F1 vs threshold"
      ],
      "metadata": {
        "id": "bcm5RBETUVFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, numpy as np, matplotlib.pyplot as plt, glob\n",
        "\n",
        "for pr_json in glob.glob(f\"{PROJECT_VAL}/val_*/PR_curve.json\"):\n",
        "    with open(pr_json) as f: pr = json.load(f)\n",
        "    conf = np.array(pr[\"confidence\"]); P = np.array(pr[\"precision\"]); R = np.array(pr[\"recall\"])\n",
        "    F1 = 2*(P*R)/(P+R+1e-9)\n",
        "    plt.figure(); plt.plot(conf, F1); plt.title(pr_json.split(\"/\")[-2]+\" F1 vs conf\")\n",
        "    plt.xlabel(\"Confidence\"); plt.ylabel(\"F1\"); plt.grid(True, alpha=.3); plt.show()\n"
      ],
      "metadata": {
        "id": "4nSZZvaDUW3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speed benchmark (ms per image) at your target resolution"
      ],
      "metadata": {
        "id": "9_h6_5XbUPgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import time, cv2, glob\n",
        "\n",
        "test_imgs = glob.glob(f\"{BASE}/data/person_dataset/images/val/*.jpg\")[:10]\n",
        "model = YOLO(str(best))  # or \"yolov8n.pt\"\n",
        "t=[]\n",
        "for im in test_imgs:\n",
        "    s=time.time(); model.predict(source=im, imgsz=640, conf=0.25, classes=[0], verbose=False)\n",
        "    t.append((time.time()-s)*1000)\n",
        "print(f\"Inference ms/img (mean±std): {np.mean(t):.1f} ± {np.std(t):.1f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaXMva_p5nu7",
        "outputId": "eb1f8bda-86da-4c88-d870-2b0fddb1a996"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Keypoint Detection"
      ],
      "metadata": {
        "id": "9HK3GYFEoxru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports, constants, folders"
      ],
      "metadata": {
        "id": "pZ10haRMe8Tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SS_DIR  = Path(BASE) / \"screens\"\n",
        "\n",
        "for p in [OUT_DIR, SS_DIR, OUT_DIR / \"Keypoint Detection\"]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Person class id for COCO\n",
        "PERSON_CLASS_ID = 0\n",
        "\n",
        "# Colors (BGR)\n",
        "C_RED  = (0, 0, 255)\n",
        "C_BLUE = (255, 0, 0)\n",
        "C_DARK = (0, 0, 0)\n",
        "\n",
        "print(\"Folders ready:\", OUT_DIR, SS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IjcbfSuc1Ly",
        "outputId": "385c9112-6086-40df-97b0-3225fb4f8c02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLO-pose loader"
      ],
      "metadata": {
        "id": "YW_DrOfGe4Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "pose_model = YOLO(\"yolov8s-pose.pt\")\n",
        "print(\"Pose model ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHvPcMaZc1JR",
        "outputId": "0872487c-deb2-4ece-9cd1-ee3071d63f7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## edges and landmark helpers (HEAD / FISTS / FEET)"
      ],
      "metadata": {
        "id": "5MIELdLye0U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO-17 skeleton edges\n",
        "COCO_EDGES = [\n",
        "    (5,7),(7,9), (6,8),(8,10),\n",
        "    (11,13),(13,15), (12,14),(14,16),\n",
        "    (5,6), (11,12), (5,11),(6,12),\n",
        "    (0,1),(1,2),(2,3),(3,4)\n",
        "]\n",
        "\n",
        "def get_kpts_xyc(result, det_index):\n",
        "\n",
        "    kobj = getattr(result, \"keypoints\", None)\n",
        "    if kobj is None:\n",
        "        return None, None\n",
        "\n",
        "    # Prefer .data\n",
        "    if hasattr(kobj, \"data\") and kobj.data is not None:\n",
        "        arr = kobj.data.cpu().numpy()  # [N, 17, 3] or [N, 17, 2]\n",
        "        if det_index >= arr.shape[0]:\n",
        "            return None, None\n",
        "        this = arr[det_index]\n",
        "        if this.shape[-1] == 3:\n",
        "            xy = this[:, :2]\n",
        "            cf = this[:, 2]\n",
        "        else:\n",
        "            xy = this[:, :2]\n",
        "            cf = np.ones((xy.shape[0],), dtype=float)\n",
        "        return xy, cf\n",
        "\n",
        "    # Fallback: .xy (positions only)\n",
        "    if hasattr(kobj, \"xy\") and kobj.xy is not None:\n",
        "        arr = kobj.xy.cpu().numpy()  # [N, 17, 2]\n",
        "        if det_index >= arr.shape[0]:\n",
        "            return None, None\n",
        "        xy = arr[det_index]\n",
        "        cf = np.ones((xy.shape[0],), dtype=float)\n",
        "        return xy, cf\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def get_head_point(xy, conf, conf_thr=0.25):\n",
        "    \"\"\"\n",
        "    A robust single \"head\" point:\n",
        "    - prefer nose (idx 0) if confident,\n",
        "    - else mean of eyes (1,2),\n",
        "    - else mean of shoulders (5,6),\n",
        "    - else fall back to nose.\n",
        "    \"\"\"\n",
        "    if xy is None:\n",
        "        return None\n",
        "    if conf is None or (len(conf)>0 and conf[0] >= conf_thr):\n",
        "        return xy[0]\n",
        "    if len(xy) > 2:\n",
        "        eyes = [xy[1], xy[2]]\n",
        "        if eyes[0] is not None and eyes[1] is not None:\n",
        "            return np.mean(np.stack(eyes), axis=0)\n",
        "    if len(xy) > 6:\n",
        "        sh = [xy[5], xy[6]]\n",
        "        if sh[0] is not None and sh[1] is not None:\n",
        "            return np.mean(np.stack(sh), axis=0)\n",
        "    return xy[0]\n",
        "\n",
        "def get_fists(xy, conf=None):\n",
        "    \"\"\"\n",
        "    Fists == wrists (left=9, right=10).\n",
        "    Returns dict {'left','right','best'}\n",
        "    \"\"\"\n",
        "    if xy is None:\n",
        "        return {\"left\": None, \"right\": None, \"best\": None}\n",
        "    lw = xy[9]  if len(xy) > 9  else None\n",
        "    rw = xy[10] if len(xy) > 10 else None\n",
        "    if conf is None:\n",
        "        best = lw if lw is not None else rw\n",
        "    else:\n",
        "        lc = conf[9]  if len(conf) > 9  else 0.0\n",
        "        rc = conf[10] if len(conf) > 10 else 0.0\n",
        "        best = lw if lc >= rc else rw\n",
        "    return {\"left\": lw, \"right\": rw, \"best\": best}\n",
        "\n",
        "def get_feet(xy):\n",
        "    \"\"\"\n",
        "    Feet == ankles (left=15, right=16). Also returns 'lower' (closer to the floor in image coords).\n",
        "    \"\"\"\n",
        "    if xy is None:\n",
        "        return {\"left\": None, \"right\": None, \"lower\": None, \"higher\": None}\n",
        "    la = xy[15] if len(xy) > 15 else None\n",
        "    ra = xy[16] if len(xy) > 16 else None\n",
        "    cand = [p for p in [la, ra] if p is not None]\n",
        "    if not cand:\n",
        "        return {\"left\": la, \"right\": ra, \"lower\": None, \"higher\": None}\n",
        "    lower = max(cand, key=lambda p: p[1])   # larger y → lower on screen\n",
        "    higher = min(cand, key=lambda p: p[1])\n",
        "    return {\"left\": la, \"right\": ra, \"lower\": lower, \"higher\": higher}\n",
        "\n",
        "def draw_landmarks(frame, head, fists, feet, color=(0, 0, 0)):\n",
        "    \"\"\"\n",
        "    Draw HEAD, LEFT/RIGHT FIST (+ ring on best), LEFT/RIGHT FOOT.\n",
        "    \"\"\"\n",
        "    # Head\n",
        "    if head is not None:\n",
        "        cv2.circle(frame, (int(head[0]), int(head[1])), 6, color, -1, cv2.LINE_AA)\n",
        "        cv2.putText(frame, \"HEAD\", (int(head[0])+6, int(head[1])-6),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Fists\n",
        "    for tag in [\"left\", \"right\"]:\n",
        "        p = fists.get(tag)\n",
        "        if p is not None:\n",
        "            cv2.circle(frame, (int(p[0]), int(p[1])), 6, color, -1, cv2.LINE_AA)\n",
        "            cv2.putText(frame, f\"{tag.upper()} FIST\", (int(p[0])+6, int(p[1])-6),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Best fist (outline ring)\n",
        "    best = fists.get(\"best\")\n",
        "    if best is not None:\n",
        "        cv2.circle(frame, (int(best[0]), int(best[1])), 10, color, 2, cv2.LINE_AA)\n",
        "\n",
        "    # Feet\n",
        "    for tag in [\"left\", \"right\"]:\n",
        "        p = feet.get(tag)\n",
        "        if p is not None:\n",
        "            cv2.circle(frame, (int(p[0]), int(p[1])), 6, color, -1, cv2.LINE_AA)\n",
        "            cv2.putText(frame, f\"{tag.upper()} FOOT\", (int(p[0])+6, int(p[1])-6),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2, cv2.LINE_AA)\n"
      ],
      "metadata": {
        "id": "6xm2G4_Gc1AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mark head / fists / feet"
      ],
      "metadata": {
        "id": "59G8TCXsetmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def track_pose_and_render_manual(\n",
        "    src_path,\n",
        "    save_prefix=\"yolov8s_pose\",\n",
        "    conf=0.35,\n",
        "    iou=0.45,\n",
        "    tracker=\"bytetrack.yaml\",\n",
        "    take_screens=5\n",
        "):\n",
        "    src = Path(src_path)\n",
        "    name = src.stem.strip().replace(\" \", \"_\")\n",
        "\n",
        "    # Probe source video\n",
        "    cap = cv2.VideoCapture(str(src))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open video: {src}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0\n",
        "    if fps <= 1: fps = 30.0\n",
        "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1280\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 720\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) or 0\n",
        "    cap.release()\n",
        "\n",
        "    # Output paths\n",
        "    out_dir = OUT_DIR / \"Keypoint Detection\"\n",
        "    out_video_path = out_dir / f\"{save_prefix}_{name}_pose.mp4\"\n",
        "    out_json_path  = out_dir / f\"{save_prefix}_{name}_pose_stats.json\"\n",
        "\n",
        "    # VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(str(out_video_path), fourcc, fps, (width, height))\n",
        "    if not writer.isOpened():\n",
        "        out_video_path = out_dir / f\"{save_prefix}_{name}_pose.avi\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(str(out_video_path), fourcc, fps, (width, height))\n",
        "        if not writer.isOpened():\n",
        "            raise RuntimeError(\"Failed to open VideoWriter for both MP4 and AVI.\")\n",
        "\n",
        "    # Screenshot positions\n",
        "    shot_positions = []\n",
        "    if total_frames > 0:\n",
        "        take = min(take_screens, total_frames) if total_frames < take_screens else take_screens\n",
        "        shot_positions = [int((i+1) * total_frames / (take+1)) for i in range(take)]\n",
        "    screenshot_buffer = {}\n",
        "\n",
        "    # Stats\n",
        "    frame_idx = 0\n",
        "    frame_counts = []\n",
        "    track_ids_seen = set()\n",
        "    id_switches = 0\n",
        "    prev_frame_ids = set()\n",
        "\n",
        "    # Stream pose tracking: persons only\n",
        "    gen = pose_model.track(\n",
        "        source=str(src),\n",
        "        conf=conf, iou=iou, classes=[PERSON_CLASS_ID],\n",
        "        tracker=tracker,\n",
        "        save=False, stream=True, verbose=False\n",
        "    )\n",
        "\n",
        "    for r in gen:\n",
        "        # Draw default overlays (boxes + skeletons)\n",
        "        frame = r.plot()\n",
        "\n",
        "        # --- Extract track IDs (for stats & color consistency) ---\n",
        "        ids = []\n",
        "        if r.boxes is not None and r.boxes.id is not None:\n",
        "            ids = [int(x) for x in r.boxes.id.cpu().numpy().tolist()]\n",
        "        frame_counts.append(len(ids))\n",
        "        new_ids = set(ids)\n",
        "        appeared = new_ids - prev_frame_ids\n",
        "        disappeared = prev_frame_ids - new_ids\n",
        "        if appeared and disappeared:\n",
        "            id_switches += min(len(appeared), len(disappeared))\n",
        "        prev_frame_ids = new_ids\n",
        "        track_ids_seen.update(ids)\n",
        "\n",
        "        # --- For each detection, read keypoints and mark HEAD/FISTS/FEET ---\n",
        "        for i, tid in enumerate(ids):\n",
        "            xy, cf = get_kpts_xyc(r, i)\n",
        "            if xy is None:\n",
        "                continue\n",
        "\n",
        "            # Choose a per-ID color (use your Red/Blue if you have mapping; here parity as simple example)\n",
        "            color = C_RED if (tid % 2 == 0) else C_BLUE\n",
        "\n",
        "            head = get_head_point(xy, cf, conf_thr=0.25)\n",
        "            fists = get_fists(xy, cf)\n",
        "            feet  = get_feet(xy)\n",
        "\n",
        "            draw_landmarks(frame, head, fists, feet, color=color)\n",
        "\n",
        "        # Save screenshots\n",
        "        if frame_idx in shot_positions:\n",
        "            screenshot_buffer[frame_idx] = frame.copy()\n",
        "\n",
        "        # Write frame\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    writer.release()\n",
        "\n",
        "    # Dump screenshots\n",
        "    for pos, img in screenshot_buffer.items():\n",
        "        cv2.imwrite(str(SS_DIR / f\"{save_prefix}_{name}_pose_frame{pos}.jpg\"), img)\n",
        "\n",
        "    # Save stats\n",
        "    stats = {\n",
        "        \"video\": src.name,\n",
        "        \"frames_processed\": frame_idx,\n",
        "        \"mean_persons_per_frame\": float(np.mean(frame_counts)) if frame_counts else 0.0,\n",
        "        \"max_persons_in_frame\": int(np.max(frame_counts)) if frame_counts else 0,\n",
        "        \"unique_track_ids\": len(track_ids_seen),\n",
        "        \"approx_id_switches\": int(id_switches),\n",
        "        \"conf\": conf, \"iou\": iou, \"tracker\": tracker,\n",
        "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"mode\": \"pose+landmarks\",\n",
        "    }\n",
        "    with open(out_json_path, \"w\") as f:\n",
        "        json.dump(stats, f, indent=2)\n",
        "\n",
        "    print(\"Saved pose+landmarks video:\", out_video_path)\n",
        "    print(\"Saved pose stats:\", out_json_path)\n",
        "    return out_video_path, out_json_path\n"
      ],
      "metadata": {
        "id": "Ehm2JyrOc0pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "ZbV-Ae6vekat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pose_generated = []\n",
        "for v in videos:\n",
        "    out_vid, out_json = track_pose_and_render_manual(v, save_prefix=\"yolov8s\")\n",
        "    pose_generated.append((out_vid, out_json))\n",
        "\n",
        "print(\"\\nPose files generated:\")\n",
        "for v, j in pose_generated:\n",
        "    print(\"-\", Path(v).name, \"|\", Path(j).name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLUJDNS9dF8Y",
        "outputId": "3cfa5beb-c906-4fb0-ba4e-b2df08d0f0e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune YOLOv8s-pose on label data"
      ],
      "metadata": {
        "id": "shsvxukm0Bpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"/content/drive/MyDrive/DS5216\"\n",
        "POSE_DATA = Path(BASE) / \"data\" / \"pose_dataset\"\n",
        "IM_ALL   = POSE_DATA / \"images\" / \"all\"\n",
        "IM_TRAIN = POSE_DATA / \"images\" / \"train\"\n",
        "IM_VAL   = POSE_DATA / \"images\" / \"val\"\n",
        "LB_ALL   = POSE_DATA / \"labels\" / \"all\"\n",
        "LB_TRAIN = POSE_DATA / \"labels\" / \"train\"\n",
        "LB_VAL   = POSE_DATA / \"labels\" / \"val\""
      ],
      "metadata": {
        "id": "VC6Y3vi0-NaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_YAML = str(POSE_DATA / \"person_pose.yaml\")\n",
        "PROJECT_TRAIN = str(Path(BASE) / \"exp_pose_train\")\n",
        "\n",
        "finetune_model = YOLO(\"yolov8s-pose.pt\")\n",
        "train_res = finetune_model.train(\n",
        "    data=DATA_YAML, imgsz=640, epochs=20, batch=16, device=0,\n",
        "    project=PROJECT_TRAIN, name=\"y8s_pose_finetuned\", verbose=False\n",
        ")\n",
        "best_weights = Path(train_res.save_dir) / \"weights\" / \"best.pt\"\n",
        "best_weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glHM-75T2xNU",
        "outputId": "22a759ca-bb3e-47c6-a5d8-389f306a730b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate YOLOv8s-pose (pretrained) vs YOLOv8s-pose (fine-tuned)"
      ],
      "metadata": {
        "id": "-tvzuL8f7utM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_VAL = Path(BASE) / \"exp_pose_eval\"\n",
        "PROJECT_VAL.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "models_to_eval = [\n",
        "    (\"y8s_pose_pretrained\", \"yolov8s-pose.pt\"),\n",
        "    (\"y8s_pose_finetuned\", str(best_weights)),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for tag, w in models_to_eval:\n",
        "    r = YOLO(w).val(\n",
        "        data=str(POSE_DATA / \"person_pose.yaml\"),\n",
        "        imgsz=640, plots=True, save_json=True,\n",
        "        project=str(PROJECT_VAL), name=f\"val_{tag}\", verbose=False\n",
        "    )\n",
        "    d = r.results_dict\n",
        "    rows.append({\n",
        "        \"model\": tag,\n",
        "        \"mAP50-95(OKS)\": d.get(\"metrics/mAP50-95(B)\", d.get(\"metrics/mAP50-95\")),\n",
        "        \"mAP50(OKS)\":    d.get(\"metrics/mAP50(B)\", d.get(\"metrics/mAP50\")),\n",
        "        \"precision\":     d.get(\"metrics/precision(B)\", d.get(\"precision\")),\n",
        "        \"recall\":        d.get(\"metrics/recall(B)\", d.get(\"recall\")),\n",
        "        \"inference_ms\":  d.get(\"speed/inference\")\n",
        "    })\n",
        "\n",
        "df_pose = pd.DataFrame(rows)\n",
        "df_pose\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "46pma4204F4N",
        "outputId": "30bbe0f0-863d-4ef4-e7c1-d4a43f5c1d06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot training loss curves for the fine-tuned model"
      ],
      "metadata": {
        "id": "PdCqKNYv9BLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, matplotlib.pyplot as plt, glob\n",
        "\n",
        "csv_path = sorted(glob.glob(f\"{PROJECT_TRAIN}/y8n_pose_finetuned/results.csv\"))[-1]\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "for col in [\"train/box_loss\",\"train/kobj_loss\",\"train/keypoint_loss\",\n",
        "            \"metrics/mAP50(B)\",\"metrics/mAP50-95(B)\"]:\n",
        "    if col in df.columns:\n",
        "        plt.figure()\n",
        "        plt.plot(df[\"epoch\"], df[col])\n",
        "        plt.title(col); plt.xlabel(\"Epoch\"); plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r6AeT3lp2xJ1",
        "outputId": "6236bca2-0433-40a8-eac0-295ba55d7326"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quick bar chart of OKS mAP"
      ],
      "metadata": {
        "id": "UuvGO27J9I4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(df_pose[\"model\"], df_pose[\"mAP50-95(OKS)\"])\n",
        "plt.ylabel(\"OKS mAP@50:95\")\n",
        "plt.title(\"Pose Model Comparison\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "2Dj2BPfW4eSp",
        "outputId": "f43a5dc2-20ec-497b-9423-ff9533f97234"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improvements\n"
      ],
      "metadata": {
        "id": "CFTYA2z-UlLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config & helpers"
      ],
      "metadata": {
        "id": "SlCnjS68Usol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIG ---\n",
        "HORIZON_FRAMES = 2       # predict ~0.07s ahead @ 30FPS\n",
        "HISTORY_FRAMES = 12      # past frames stored per fighter\n",
        "EMA_ALPHA = 0.25         # smoothing for probabilities\n",
        "WARMUP_FRAMES = 15       # frames to decide Red/Blue (left/right)\n",
        "FPS_FALLBACK = 30.0\n",
        "\n",
        "# Colors (BGR)\n",
        "C_RED   = (0, 0, 255)\n",
        "C_BLUE  = (255, 0, 0)\n",
        "C_GRAY  = (160, 160, 160)\n",
        "\n",
        "# COCO-17 skeleton edges (Ultralytics order)\n",
        "COCO_EDGES = [\n",
        "    (5,7),(7,9), (6,8),(8,10),\n",
        "    (11,13),(13,15), (12,14),(14,16),\n",
        "    (5,6), (11,12), (5,11),(6,12),\n",
        "    (0,1),(1,2),(2,3),(3,4)\n",
        "]\n",
        "\n",
        "def draw_skeleton(frame, kpts_xy, color, radius=3, thick=2):\n",
        "    if kpts_xy is None: return\n",
        "    for a,b in COCO_EDGES:\n",
        "        if a < len(kpts_xy) and b < len(kpts_xy):\n",
        "            xa,ya = kpts_xy[a]; xb,yb = kpts_xy[b]\n",
        "            if xa>0 and ya>0 and xb>0 and yb>0:\n",
        "                cv2.line(frame,(int(xa),int(ya)),(int(xb),int(yb)), color, thick, cv2.LINE_AA)\n",
        "    for (x,y) in kpts_xy:\n",
        "        if x>0 and y>0:\n",
        "            cv2.circle(frame,(int(x),int(y)), radius, color, -1, cv2.LINE_AA)\n",
        "\n",
        "# dashed skeleton overlay\n",
        "def draw_dashed_line(img, p1, p2, color, thickness=2, dash=10, gap=7):\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    x1, y1 = int(p1[0]), int(p1[1])\n",
        "    x2, y2 = int(p2[0]), int(p2[1])\n",
        "\n",
        "    # Clamp points to image boundaries\n",
        "    x1 = max(0, min(w-1, x1)); y1 = max(0, min(h-1, y1))\n",
        "    x2 = max(0, min(w-1, x2)); y2 = max(0, min(h-1, y2))\n",
        "\n",
        "    dist = int(np.hypot(x2 - x1, y2 - y1))\n",
        "    if dist <= 0:\n",
        "        return\n",
        "\n",
        "    dx, dy = (x2 - x1) / dist, (y2 - y1) / dist\n",
        "\n",
        "    n = 0\n",
        "    while n * (dash + gap) < dist:\n",
        "        start = n * (dash + gap)\n",
        "        end = min(start + dash, dist)\n",
        "\n",
        "        xs = int(x1 + dx * start); ys = int(y1 + dy * start)\n",
        "        xe = int(x1 + dx * end);   ye = int(y1 + dy * end)\n",
        "\n",
        "        # Clip each segment before drawing\n",
        "        xs = max(0, min(w-1, xs)); ys = max(0, min(h-1, ys))\n",
        "        xe = max(0, min(w-1, xe)); ye = max(0, min(h-1, ye))\n",
        "\n",
        "        cv2.line(img, (xs, ys), (xe, ye), color, thickness, cv2.LINE_AA)\n",
        "        n += 1\n",
        "\n",
        "        n += 1\n",
        "\n",
        "def draw_skeleton_dashed(frame, kpts_xy, color, joint_radius=3, thick=2, dash=10, gap=7):\n",
        "    if kpts_xy is None: return\n",
        "    for a,b in COCO_EDGES:\n",
        "        if a < len(kpts_xy) and b < len(kpts_xy):\n",
        "            xa,ya = kpts_xy[a]; xb,yb = kpts_xy[b]\n",
        "            if xa>0 and ya>0 and xb>0 and yb>0:\n",
        "                draw_dashed_line(frame, (xa,ya), (xb,yb), color, thickness=thick, dash=dash, gap=gap)\n",
        "    for (x,y) in kpts_xy:\n",
        "        if x>0 and y>0:\n",
        "            cv2.circle(frame,(int(x),int(y)), joint_radius+1, color, 2, cv2.LINE_AA)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, alpha=0.25, init_vec=None):\n",
        "        self.alpha = alpha\n",
        "        self.state = None if init_vec is None else np.array(init_vec, dtype=float)\n",
        "    def update(self, vec):\n",
        "        v = np.array(vec, dtype=float)\n",
        "        if self.state is None: self.state = v\n",
        "        else: self.state = self.alpha*v + (1.0-self.alpha)*self.state\n",
        "        return self.state.copy()\n",
        "\n",
        "def softmax(z):\n",
        "    z = np.array(z, dtype=float); z -= np.max(z); e = np.exp(z)\n",
        "    return e / (np.sum(e) + 1e-9)\n",
        "\n",
        "def normalize01(x, lo, hi):\n",
        "    return float(np.clip((x - lo) / (hi - lo + 1e-9), 0.0, 1.0))\n",
        "\n",
        "# torso helpers (for fitting predicted pose)\n",
        "def torso_center(kpts):\n",
        "    if kpts is None: return None\n",
        "    idxs = [5,6,11,12]\n",
        "    pts = [kpts[i] for i in idxs if i < len(kpts)]\n",
        "    pts = np.array([p for p in pts if p is not None])\n",
        "    if len(pts) == 0: return None\n",
        "    return np.nanmean(pts, axis=0)\n",
        "\n",
        "def align_pose_to_torso(curr, fut):\n",
        "    if curr is None or fut is None: return fut\n",
        "    c_curr, c_fut = torso_center(curr), torso_center(fut)\n",
        "    if c_curr is None or c_fut is None: return fut\n",
        "    shift = c_curr - c_fut\n",
        "    out = fut.copy(); out += shift\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "V5TsXCypUnrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heuristic probabilities (kick/punch/block/none)"
      ],
      "metadata": {
        "id": "CZms3tWCU1C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kpt_speed(curr, prev):\n",
        "    if curr is None or prev is None: return 0.0\n",
        "    diffs = curr - prev\n",
        "    return float(np.linalg.norm(diffs, axis=1).mean())\n",
        "\n",
        "def height_rel(kpt, ref_y):\n",
        "    if kpt is None: return 0.0\n",
        "    return float(max(0.0, ref_y - kpt[1]))  # above hips (px)\n",
        "\n",
        "def heuristic_probs(self_hist, opp_hist, frame_h):\n",
        "    curr = self_hist[-1] if len(self_hist)>0 else None\n",
        "    prev = self_hist[-2] if len(self_hist)>1 else None\n",
        "    opp  = opp_hist[-1] if (opp_hist and len(opp_hist)>0) else None\n",
        "\n",
        "    def pt(k, i):\n",
        "        return None if (k is None or i>=len(k)) else k[i]\n",
        "\n",
        "    lw, rw = pt(curr, 9),  pt(curr,10)   # wrists\n",
        "    la, ra = pt(curr,15), pt(curr,16)    # ankles\n",
        "    lh, rh = pt(curr,11), pt(curr,12)    # hips\n",
        "    nose   = pt(curr,0)\n",
        "\n",
        "    v_all = kpt_speed(curr, prev)\n",
        "    opp_head = opp[0] if opp is not None else None\n",
        "\n",
        "    def reach_prob(hand):\n",
        "        if hand is None or opp_head is None: return 0.0\n",
        "        d = np.linalg.norm(hand - opp_head)\n",
        "        return 1.0 - normalize01(d, 0.05*frame_h, 0.6*frame_h)\n",
        "\n",
        "    p_punch = max(reach_prob(lw), reach_prob(rw)) * normalize01(v_all, 1.0, 25.0)\n",
        "\n",
        "    hip_y  = np.nanmean([rh[1] if rh is not None else frame_h, lh[1] if lh is not None else frame_h])\n",
        "    foot_h = max(height_rel(la, hip_y), height_rel(ra, hip_y))\n",
        "    p_kick = normalize01(foot_h, 0.0, 60.0) * normalize01(v_all, 1.0, 25.0)\n",
        "\n",
        "    def near_face(hand):\n",
        "        if hand is None or nose is None: return 0.0\n",
        "        d = np.linalg.norm(hand - nose)\n",
        "        return 1.0 - normalize01(d, 0.03*frame_h, 0.25*frame_h)\n",
        "    guard   = max(near_face(lw), near_face(rw))\n",
        "    p_block = guard * (1.0 - normalize01(v_all, 10.0, 35.0))\n",
        "\n",
        "    logits = np.array([p_kick, p_punch, p_block, 0.3*(1.0 - max(p_kick,p_punch,p_block)) + 0.05])\n",
        "    probs  = softmax(logits * 3.0)\n",
        "    return {\"kick\": float(probs[0]), \"punch\": float(probs[1]), \"block\": float(probs[2]), \"none\": float(probs[3])}\n"
      ],
      "metadata": {
        "id": "p7AYrR2lUoJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future pose (constant velocity) + torso/head blending"
      ],
      "metadata": {
        "id": "F0JmaoSlYPIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_future_pose(kpts_hist, horizon=HORIZON_FRAMES, dt=1.0):\n",
        "    if len(kpts_hist) < 3 or kpts_hist[-1] is None or kpts_hist[-2] is None:\n",
        "        return None\n",
        "    p2 = kpts_hist[-1]; p1 = kpts_hist[-2]\n",
        "    v  = (p2 - p1) / max(dt, 1e-9)\n",
        "    return p2 + v * horizon\n",
        "\n",
        "HEAD_FACE = [0,1,2,3,4]   # nose, eyes, ears\n",
        "TORSO     = [5,6,11,12]   # shoulders & hips\n",
        "\n",
        "def blend_future_pose(curr, fut, head_blend=0.85):\n",
        "    if curr is None or fut is None:\n",
        "        return fut if fut is not None else curr\n",
        "    fut = fut.copy(); curr = curr.copy()\n",
        "    for idx in TORSO:\n",
        "        if idx < len(fut) and idx < len(curr):\n",
        "            fut[idx] = curr[idx]\n",
        "    for idx in HEAD_FACE:\n",
        "        if idx < len(fut) and idx < len(curr):\n",
        "            fut[idx] = head_blend * curr[idx] + (1.0 - head_blend) * fut[idx]\n",
        "    return fut\n"
      ],
      "metadata": {
        "id": "YbqzS6shUoG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal probability overlay (top-right, no background)"
      ],
      "metadata": {
        "id": "0TUyKWQCYYxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_probs_overlay(frame, probs_by_id, id_to_role, margin=12):\n",
        "\n",
        "    h, w = frame.shape[:2]\n",
        "    x_right = w - margin\n",
        "    y = margin + 10\n",
        "    bar_height = 16\n",
        "    bar_length = 150\n",
        "    line_gap = 28\n",
        "\n",
        "    # Title\n",
        "    title = \"Probabilities\"\n",
        "    (tw, th), _ = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
        "    cv2.putText(frame, title, (x_right - tw, y),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 2, cv2.LINE_AA)\n",
        "    y += line_gap\n",
        "\n",
        "    # Order fighters consistently (Red then Blue)\n",
        "    order = []\n",
        "    for tid in probs_by_id.keys():\n",
        "        role = id_to_role.get(tid, \"Fighter\")\n",
        "        order.append((0 if role==\"Red Fighter\" else 1, tid))\n",
        "    order.sort()\n",
        "\n",
        "    for _, tid in order:\n",
        "        role = id_to_role.get(tid, \"Fighter\")\n",
        "        color = C_RED if role==\"Red Fighter\" else C_BLUE\n",
        "\n",
        "        # Fighter header\n",
        "        label = f\"{role} (ID {tid})\"\n",
        "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.55, 2)\n",
        "        cv2.putText(frame, label, (x_right - tw, y),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0,0,0), 2, cv2.LINE_AA)\n",
        "        y += line_gap\n",
        "\n",
        "        # Draw 3 bars: Kick, Punch, Block\n",
        "        for action in [\"kick\", \"punch\", \"block\"]:\n",
        "            p = float(probs_by_id[tid][action])\n",
        "            bar_w = int(bar_length * p)\n",
        "            x1 = x_right - bar_length\n",
        "            x2 = x_right\n",
        "\n",
        "            # Rail\n",
        "            cv2.line(frame, (x1, y), (x2, y), (50,50,50), 2)\n",
        "            # Value bar\n",
        "            cv2.line(frame, (x2 - bar_w, y), (x2, y), color, 4)\n",
        "\n",
        "            # Text\n",
        "            txt = f\"{action.capitalize()} {p:.2f}\"\n",
        "            (tw, th), _ = cv2.getTextSize(txt, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "            cv2.putText(frame, txt, (x1 - tw - 8, y + 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2, cv2.LINE_AA)\n",
        "            y += bar_height + 8\n",
        "\n",
        "        y += 6  # gap after fighter\n"
      ],
      "metadata": {
        "id": "5yHplrP4YYYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runner: overlay everything on the original frame"
      ],
      "metadata": {
        "id": "kJBH9YkpYfhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "\n",
        "def run_overlay_video(\n",
        "    src_path,\n",
        "    save_prefix=\"overlay\",\n",
        "    conf=0.35, iou=0.45,\n",
        "    tracker=\"bytetrack.yaml\"\n",
        "):\n",
        "    src = Path(src_path)\n",
        "    name = src.stem.strip().replace(\" \", \"_\")\n",
        "\n",
        "    # probe\n",
        "    cap = cv2.VideoCapture(str(src))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Cannot open: {src}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS) or FPS_FALLBACK\n",
        "    if fps <= 1: fps = FPS_FALLBACK\n",
        "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 1280\n",
        "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 720\n",
        "    cap.release()\n",
        "\n",
        "    # writer\n",
        "    out_path = OUT_DIR /\"Improvements\"/ f\"{save_prefix}_{name}_overlay.mp4\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(str(out_path), fourcc, fps, (W, H))\n",
        "    if not writer.isOpened():\n",
        "        out_path = OUT_DIR / f\"{save_prefix}_{name}_overlay.avi\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(str(out_path), fourcc, fps, (W, H))\n",
        "        if not writer.isOpened():\n",
        "            raise RuntimeError(\"VideoWriter open failed.\")\n",
        "\n",
        "    # state\n",
        "    id_to_hist = defaultdict(lambda: deque(maxlen=HISTORY_FRAMES))\n",
        "    id_to_prob_ema = defaultdict(lambda: EMA(EMA_ALPHA, [0.12,0.12,0.12]))\n",
        "    id_to_role = {}\n",
        "    warm_pos = defaultdict(list)\n",
        "    frame_idx = 0\n",
        "\n",
        "    # stream\n",
        "    gen = pose_model.track(\n",
        "        source=str(src), conf=conf, iou=iou, classes=[PERSON_CLASS_ID],\n",
        "        tracker=tracker, save=False, stream=True, verbose=False\n",
        "    )\n",
        "\n",
        "    for r in gen:\n",
        "        frame = r.orig_img.copy() if hasattr(r, \"orig_img\") else r.plot()\n",
        "        fh, fw = frame.shape[:2]\n",
        "\n",
        "        # detections\n",
        "        ids, boxes = [], []\n",
        "        if r.boxes is not None:\n",
        "            if r.boxes.id is not None:\n",
        "                ids = [int(x) for x in r.boxes.id.cpu().numpy().tolist()]\n",
        "            if r.boxes.xyxy is not None:\n",
        "                boxes = r.boxes.xyxy.cpu().numpy().tolist()\n",
        "        # keypoints (n,17,2)\n",
        "        if hasattr(r, \"keypoints\") and r.keypoints is not None:\n",
        "            try:\n",
        "                kps = r.keypoints.xy.cpu().numpy()\n",
        "            except:\n",
        "                kps = r.keypoints.data[..., :2].cpu().numpy()\n",
        "        else:\n",
        "            kps = []\n",
        "\n",
        "        # histories\n",
        "        cur_by_id = {}\n",
        "        for i, tid in enumerate(ids):\n",
        "            this_k = kps[i] if i < len(kps) else None\n",
        "            id_to_hist[tid].append(this_k)\n",
        "            cur_by_id[tid] = this_k\n",
        "\n",
        "        # roles (left/right after warmup)\n",
        "        if frame_idx < WARMUP_FRAMES:\n",
        "            for i, tid in enumerate(ids):\n",
        "                if i < len(boxes) and boxes[i] is not None:\n",
        "                    x1,y1,x2,y2 = boxes[i]\n",
        "                    warm_pos[tid].append(0.5*(x1+x2))\n",
        "        if frame_idx == WARMUP_FRAMES and not id_to_role:\n",
        "            means = [(tid, np.mean(xs)) for tid, xs in warm_pos.items() if len(xs)>0]\n",
        "            means.sort(key=lambda t: t[1])  # left→right\n",
        "            if len(means) >= 1: id_to_role[means[0][0]] = \"Red Fighter\"\n",
        "            if len(means) >= 2: id_to_role[means[1][0]] = \"Blue Fighter\"\n",
        "\n",
        "        # per-id probs & predicted pose (fitted)\n",
        "        ids_sorted = list(cur_by_id.keys())\n",
        "        probs_for_overlay, fut_fitted = {}, {}\n",
        "        for tid in ids_sorted:\n",
        "            opp_tid = None\n",
        "            if len(ids_sorted) > 1:\n",
        "                opp_tid = ids_sorted[1] if ids_sorted[0]==tid else ids_sorted[0]\n",
        "\n",
        "            self_hist = id_to_hist[tid]\n",
        "            opp_hist  = id_to_hist[opp_tid] if opp_tid is not None else deque(maxlen=HISTORY_FRAMES)\n",
        "\n",
        "            p = heuristic_probs(self_hist, opp_hist, fh)\n",
        "            sm = id_to_prob_ema[tid].update([p[\"kick\"], p[\"punch\"], p[\"block\"]])\n",
        "            probs_for_overlay[tid] = {\"kick\": float(sm[0]), \"punch\": float(sm[1]), \"block\": float(sm[2])}\n",
        "\n",
        "            fut = predict_future_pose(self_hist, horizon=HORIZON_FRAMES)\n",
        "            fitted = blend_future_pose(cur_by_id.get(tid), fut, head_blend=0.85)\n",
        "            fitted = align_pose_to_torso(cur_by_id.get(tid), fitted)\n",
        "            fut_fitted[tid] = fitted\n",
        "\n",
        "        # draw current boxes/labels/skeletons\n",
        "        for i, tid in enumerate(ids):\n",
        "            role = id_to_role.get(tid, \"Fighter\")\n",
        "            col  = C_RED if role==\"Red Fighter\" else (C_BLUE if role==\"Blue Fighter\" else (0,255,0))\n",
        "            if i < len(boxes):\n",
        "                x1,y1,x2,y2 = map(int, boxes[i])\n",
        "                cv2.rectangle(frame,(x1,y1),(x2,y2), col, 2)\n",
        "                cv2.putText(frame,f\"{role} (ID {tid})\",(x1, max(20,y1-10)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,0.7,col,2,cv2.LINE_AA)\n",
        "            if i < len(kps):\n",
        "                draw_skeleton(frame, kps[i], col, radius=3, thick=2)\n",
        "\n",
        "        # draw predicted (dashed) on top\n",
        "        for tid, fut in fut_fitted.items():\n",
        "            role = id_to_role.get(tid, \"Fighter\")\n",
        "            col  = C_RED if role==\"Red Fighter\" else (C_BLUE if role==\"Blue Fighter\" else (0,180,0))\n",
        "            if fut is not None:\n",
        "                draw_skeleton_dashed(frame, fut, col, joint_radius=3, thick=2, dash=10, gap=7)\n",
        "\n",
        "        # top-right probabilities\n",
        "        draw_probs_overlay(frame, probs_for_overlay, id_to_role, margin=12)\n",
        "\n",
        "        writer.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    writer.release()\n",
        "    print(\"Saved overlay video:\", out_path)\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "6G7xV9HYYhnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "pDU5loXJU8yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overlay_outputs = []\n",
        "for v in videos:\n",
        "    overlay_outputs.append(run_overlay_video(v, save_prefix=\"tri\", tracker=\"bytetrack.yaml\"))\n",
        "overlay_outputs[:2]\n"
      ],
      "metadata": {
        "id": "bScZ3zZDU77s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c13a69-07c5-438e-eb27-65dfcc65bca6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}